#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RAGçŸ¥è¯†åº“æ¼”ç¤ºç¨‹åº
æ•´åˆQdrantå‘é‡æ•°æ®åº“å’ŒOllamaæ¨¡å‹å®ç°æ£€ç´¢å¢å¼ºç”Ÿæˆ
"""

import os
import sys
import time
from typing import List, Dict, Any, Optional
from pathlib import Path
from dotenv import load_dotenv
from loguru import logger
from tqdm import tqdm

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from document_processor import DocumentProcessor
from vector_store import VectorStore
from ollama_client import OllamaClient

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class RAGSystem:
    """
    RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ç³»ç»Ÿä¸»ç±»
    """
    
    def __init__(self):
        """
        åˆå§‹åŒ–RAGç³»ç»Ÿ
        """
        logger.info("åˆå§‹åŒ–RAGç³»ç»Ÿ...")
        
        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.document_processor = DocumentProcessor(
            chunk_size=int(os.getenv('CHUNK_SIZE', '512')),
            chunk_overlap=int(os.getenv('CHUNK_OVERLAP', '50'))
        )
        
        self.vector_store = VectorStore()
        self.ollama_client = OllamaClient()
        
        # é…ç½®å‚æ•°
        self.top_k_results = int(os.getenv('TOP_K_RESULTS', '5'))
        self.similarity_threshold = float(os.getenv('SIMILARITY_THRESHOLD', '0.7'))
        self.system_prompt = os.getenv('SYSTEM_PROMPT', 
            'ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œè¯·æ ¹æ®æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯šå®åœ°è¯´æ˜ã€‚')
        
        logger.info("RAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def check_system_status(self) -> Dict[str, bool]:
        """
        æ£€æŸ¥ç³»ç»Ÿå„ç»„ä»¶çŠ¶æ€
        
        Returns:
            Dict[str, bool]: å„ç»„ä»¶çŠ¶æ€
        """
        status = {
            'ollama': self.ollama_client.check_connection(),
            'qdrant': self.vector_store.check_connection()
        }
        
        logger.info(f"ç³»ç»ŸçŠ¶æ€æ£€æŸ¥: {status}")
        return status
    
    def add_document(self, file_path: str) -> bool:
        """
        æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“
        
        Args:
            file_path (str): æ–‡æ¡£æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: æ·»åŠ æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info(f"å¼€å§‹æ·»åŠ æ–‡æ¡£: {file_path}")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(file_path):
                logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return False
            
            # å¤„ç†æ–‡æ¡£
            chunks = self.document_processor.process_document(file_path)
            if not chunks:
                logger.error(f"æ–‡æ¡£å¤„ç†å¤±è´¥: {file_path}")
                return False
            
            logger.info(f"æ–‡æ¡£åˆ†å—å®Œæˆï¼Œå…±{len(chunks)}ä¸ªå—")
            
            # ç”Ÿæˆå‘é‡
            vectors = []
            metadata_list = []
            
            logger.info("å¼€å§‹ç”Ÿæˆå‘é‡åµŒå…¥...")
            for chunk in tqdm(chunks, desc="ç”Ÿæˆå‘é‡"):
                # è·å–æ–‡æœ¬åµŒå…¥
                embedding = self.ollama_client.get_embedding(chunk['text'])
                if embedding:
                    vectors.append(embedding)
                    
                    # å‡†å¤‡å…ƒæ•°æ®
                    metadata = {
                        'text': chunk['text'],
                        'source_file': chunk['source_file'],
                        'source_path': chunk['source_path'],
                        'chunk_id': chunk['id'],
                        'start_pos': chunk['start_pos'],
                        'end_pos': chunk['end_pos'],
                        'length': chunk['length'],
                        'timestamp': time.time()
                    }
                    metadata_list.append(metadata)
                else:
                    logger.warning(f"æ— æ³•ç”ŸæˆåµŒå…¥å‘é‡: chunk {chunk['id']}")
            
            if not vectors:
                logger.error("æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•å‘é‡")
                return False
            
            # å­˜å‚¨å‘é‡
            logger.info(f"å¼€å§‹å­˜å‚¨{len(vectors)}ä¸ªå‘é‡...")
            point_ids = self.vector_store.add_vectors(vectors, metadata_list)
            
            logger.info(f"æ–‡æ¡£æ·»åŠ æˆåŠŸ: {file_path}, å­˜å‚¨äº†{len(point_ids)}ä¸ªå‘é‡")
            return True
            
        except Exception as e:
            logger.error(f"æ·»åŠ æ–‡æ¡£å¤±è´¥: {e}")
            return False
    
    def add_text(self, text: str, source_name: str = "ç”¨æˆ·è¾“å…¥") -> bool:
        """
        æ·»åŠ æ–‡æœ¬åˆ°çŸ¥è¯†åº“
        
        Args:
            text (str): æ–‡æœ¬å†…å®¹
            source_name (str): æ¥æºåç§°
            
        Returns:
            bool: æ·»åŠ æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info(f"å¼€å§‹æ·»åŠ æ–‡æœ¬: {source_name}")
            
            # å¤„ç†æ–‡æœ¬
            chunks = self.document_processor.process_text(text, source_name)
            if not chunks:
                logger.error("æ–‡æœ¬å¤„ç†å¤±è´¥")
                return False
            
            # ç”Ÿæˆå‘é‡å¹¶å­˜å‚¨
            vectors = []
            metadata_list = []
            
            for chunk in tqdm(chunks, desc="ç”Ÿæˆå‘é‡"):
                embedding = self.ollama_client.get_embedding(chunk['text'])
                if embedding:
                    vectors.append(embedding)
                    
                    metadata = {
                        'text': chunk['text'],
                        'source_file': chunk['source_file'],
                        'source_path': chunk['source_path'],
                        'chunk_id': chunk['id'],
                        'start_pos': chunk['start_pos'],
                        'end_pos': chunk['end_pos'],
                        'length': chunk['length'],
                        'timestamp': time.time()
                    }
                    metadata_list.append(metadata)
            
            if vectors:
                point_ids = self.vector_store.add_vectors(vectors, metadata_list)
                logger.info(f"æ–‡æœ¬æ·»åŠ æˆåŠŸ: {source_name}, å­˜å‚¨äº†{len(point_ids)}ä¸ªå‘é‡")
                return True
            else:
                logger.error("æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•å‘é‡")
                return False
                
        except Exception as e:
            logger.error(f"æ·»åŠ æ–‡æœ¬å¤±è´¥: {e}")
            return False
    
    def search_knowledge(self, query: str) -> List[Dict[str, Any]]:
        """
        åœ¨çŸ¥è¯†åº“ä¸­æœç´¢ç›¸å…³ä¿¡æ¯
        
        Args:
            query (str): æŸ¥è¯¢æ–‡æœ¬
            
        Returns:
            List[Dict[str, Any]]: æœç´¢ç»“æœ
        """
        try:
            logger.info(f"æœç´¢æŸ¥è¯¢: {query}")
            
            # ç”ŸæˆæŸ¥è¯¢å‘é‡
            query_embedding = self.ollama_client.get_embedding(query)
            if not query_embedding:
                logger.error("æ— æ³•ç”ŸæˆæŸ¥è¯¢å‘é‡")
                return []
            
            # æœç´¢ç›¸ä¼¼å‘é‡
            results = self.vector_store.search_similar(
                query_vector=query_embedding,
                top_k=self.top_k_results,
                score_threshold=self.similarity_threshold
            )
            
            logger.info(f"æœç´¢å®Œæˆï¼Œæ‰¾åˆ°{len(results)}ä¸ªç›¸å…³ç»“æœ")
            return results
            
        except Exception as e:
            logger.error(f"æœç´¢å¤±è´¥: {e}")
            return []
    
    def generate_answer(self, query: str, search_results: List[Dict[str, Any]]) -> str:
        """
        åŸºäºæœç´¢ç»“æœç”Ÿæˆç­”æ¡ˆ
        
        Args:
            query (str): ç”¨æˆ·æŸ¥è¯¢
            search_results (List[Dict[str, Any]]): æœç´¢ç»“æœ
            
        Returns:
            str: ç”Ÿæˆçš„ç­”æ¡ˆ
        """
        try:
            # æ„å»ºä¸Šä¸‹æ–‡
            context_parts = []
            for i, result in enumerate(search_results):
                score = result['score']
                text = result['payload']['text']
                source = result['payload']['source_file']
                
                context_parts.append(
                    f"[å‚è€ƒ{i+1}] (æ¥æº: {source}, ç›¸ä¼¼åº¦: {score:.3f})\n{text}\n"
                )
            
            context = "\n".join(context_parts)
            
            # ç”Ÿæˆå›ç­”
            logger.info("å¼€å§‹ç”Ÿæˆç­”æ¡ˆ...")
            answer = self.ollama_client.generate_response(
                prompt=query,
                context=context,
                system_prompt=self.system_prompt
            )
            
            if answer:
                logger.info("ç­”æ¡ˆç”ŸæˆæˆåŠŸ")
                return answer
            else:
                logger.error("ç­”æ¡ˆç”Ÿæˆå¤±è´¥")
                return "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç”Ÿæˆç­”æ¡ˆã€‚è¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®æˆ–é‡è¯•ã€‚"
                
        except Exception as e:
            logger.error(f"ç”Ÿæˆç­”æ¡ˆå¤±è´¥: {e}")
            return f"ç”Ÿæˆç­”æ¡ˆæ—¶å‡ºç°é”™è¯¯: {e}"
    
    def ask(self, question: str) -> Dict[str, Any]:
        """
        å®Œæ•´çš„é—®ç­”æµç¨‹
        
        Args:
            question (str): ç”¨æˆ·é—®é¢˜
            
        Returns:
            Dict[str, Any]: åŒ…å«ç­”æ¡ˆå’Œç›¸å…³ä¿¡æ¯çš„ç»“æœ
        """
        start_time = time.time()
        
        # æœç´¢ç›¸å…³çŸ¥è¯†
        search_results = self.search_knowledge(question)
        
        if not search_results:
            return {
                'question': question,
                'answer': 'æŠ±æ­‰ï¼Œæˆ‘åœ¨çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯æ¥å›ç­”æ‚¨çš„é—®é¢˜ã€‚',
                'sources': [],
                'search_time': time.time() - start_time,
                'total_time': time.time() - start_time
            }
        
        search_time = time.time() - start_time
        
        # ç”Ÿæˆç­”æ¡ˆ
        answer = self.generate_answer(question, search_results)
        
        total_time = time.time() - start_time
        
        # æ•´ç†æ¥æºä¿¡æ¯
        sources = []
        for result in search_results:
            sources.append({
                'source_file': result['payload']['source_file'],
                'text_snippet': result['payload']['text'][:100] + '...',
                'similarity_score': result['score']
            })
        
        return {
            'question': question,
            'answer': answer,
            'sources': sources,
            'search_time': search_time,
            'total_time': total_time
        }
    
    def get_knowledge_base_stats(self) -> Dict[str, Any]:
        """
        è·å–çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict[str, Any]: ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            collection_info = self.vector_store.get_collection_info()
            point_count = self.vector_store.count_points()
            
            return {
                'total_documents': point_count,
                'collection_info': collection_info,
                'embedding_dimension': self.vector_store.embedding_dimension,
                'chunk_size': self.document_processor.chunk_size,
                'chunk_overlap': self.document_processor.chunk_overlap
            }
        except Exception as e:
            logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    def clear_knowledge_base(self) -> bool:
        """
        æ¸…ç©ºçŸ¥è¯†åº“
        
        Returns:
            bool: æ¸…ç©ºæ˜¯å¦æˆåŠŸ
        """
        try:
            return self.vector_store.clear_collection()
        except Exception as e:
            logger.error(f"æ¸…ç©ºçŸ¥è¯†åº“å¤±è´¥: {e}")
            return False


def interactive_demo():
    """
    äº¤äº’å¼æ¼”ç¤ºç¨‹åº
    """
    print("ğŸš€ RAGçŸ¥è¯†åº“ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 50)
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    try:
        rag = RAGSystem()
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
    status = rag.check_system_status()
    if not all(status.values()):
        print("âš ï¸  ç³»ç»Ÿç»„ä»¶çŠ¶æ€å¼‚å¸¸:")
        for component, is_ok in status.items():
            print(f"  {component}: {'âœ…' if is_ok else 'âŒ'}")
        print("\nè¯·æ£€æŸ¥Ollamaå’ŒQdrantæœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ")
        return
    
    print("âœ… ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸï¼Œæ‰€æœ‰ç»„ä»¶æ­£å¸¸")
    
    while True:
        print("\n" + "=" * 50)
        print("è¯·é€‰æ‹©æ“ä½œ:")
        print("1. æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“")
        print("2. æ·»åŠ æ–‡æœ¬åˆ°çŸ¥è¯†åº“")
        print("3. é—®ç­”æŸ¥è¯¢")
        print("4. æŸ¥çœ‹çŸ¥è¯†åº“ç»Ÿè®¡")
        print("5. æ¸…ç©ºçŸ¥è¯†åº“")
        print("6. é€€å‡º")
        
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-6): ").strip()
        
        if choice == '1':
            file_path = input("è¯·è¾“å…¥æ–‡æ¡£è·¯å¾„: ").strip()
            if file_path:
                success = rag.add_document(file_path)
                print(f"{'âœ… æ–‡æ¡£æ·»åŠ æˆåŠŸ' if success else 'âŒ æ–‡æ¡£æ·»åŠ å¤±è´¥'}")
        
        elif choice == '2':
            text = input("è¯·è¾“å…¥æ–‡æœ¬å†…å®¹: ").strip()
            source_name = input("è¯·è¾“å…¥æ¥æºåç§° (å¯é€‰): ").strip() or "ç”¨æˆ·è¾“å…¥"
            if text:
                success = rag.add_text(text, source_name)
                print(f"{'âœ… æ–‡æœ¬æ·»åŠ æˆåŠŸ' if success else 'âŒ æ–‡æœ¬æ·»åŠ å¤±è´¥'}")
        
        elif choice == '3':
            question = input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ").strip()
            if question:
                print("\nğŸ¤” æ€è€ƒä¸­...")
                result = rag.ask(question)
                
                print(f"\nğŸ“ é—®é¢˜: {result['question']}")
                print(f"\nğŸ¤– å›ç­”:\n{result['answer']}")
                
                if result['sources']:
                    print(f"\nğŸ“š å‚è€ƒæ¥æº ({len(result['sources'])}ä¸ª):")
                    for i, source in enumerate(result['sources'], 1):
                        print(f"  {i}. {source['source_file']} (ç›¸ä¼¼åº¦: {source['similarity_score']:.3f})")
                        print(f"     {source['text_snippet']}")
                
                print(f"\nâ±ï¸  æœç´¢è€—æ—¶: {result['search_time']:.2f}ç§’")
                print(f"â±ï¸  æ€»è€—æ—¶: {result['total_time']:.2f}ç§’")
        
        elif choice == '4':
            stats = rag.get_knowledge_base_stats()
            if stats:
                print("\nğŸ“Š çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯:")
                print(f"  æ€»æ–‡æ¡£å—æ•°: {stats.get('total_documents', 0)}")
                print(f"  å‘é‡ç»´åº¦: {stats.get('embedding_dimension', 0)}")
                print(f"  åˆ†å—å¤§å°: {stats.get('chunk_size', 0)}")
                print(f"  åˆ†å—é‡å : {stats.get('chunk_overlap', 0)}")
            else:
                print("âŒ æ— æ³•è·å–ç»Ÿè®¡ä¿¡æ¯")
        
        elif choice == '5':
            confirm = input("ç¡®è®¤æ¸…ç©ºçŸ¥è¯†åº“ï¼Ÿ(y/N): ").strip().lower()
            if confirm == 'y':
                success = rag.clear_knowledge_base()
                print(f"{'âœ… çŸ¥è¯†åº“å·²æ¸…ç©º' if success else 'âŒ æ¸…ç©ºå¤±è´¥'}")
        
        elif choice == '6':
            print("ğŸ‘‹ å†è§ï¼")
            break
        
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•")


if __name__ == "__main__":
    # é…ç½®æ—¥å¿—
    logger.remove()
    logger.add(sys.stderr, level="INFO", format="{time:HH:mm:ss} | {level} | {message}")
    
    # è¿è¡Œäº¤äº’å¼æ¼”ç¤º
    interactive_demo()